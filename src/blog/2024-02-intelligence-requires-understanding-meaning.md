---
title: Intelligence requires understanding & meaning
date: 2024-02-25
categories:
  - Critique
  - Technology
updatedDate: 
updateDescription: 
tags:
  - AI
location: 
coverImage: 
summary: A second post venting some of my frustration with AI, the hype and the reality of it.
---
OK, here's my position: intelligence requires understanding & meaning. Therefore, if you want to call something intelligent, then it must be able to exhibit understanding and meaning. AI, as it stands, can exhibit neither, which leaves it as being *Artificial*. Or *fake* ‚Äì which is technically correct.
 
I am over the promises and hype behind AI. What's become abundantly clear to me over the last year is that it's ALL üëè JUST üëè HYPE üëè. To go around claiming that ChatGPT is AI is not only misleading, it's grossly overstating its capabilities. My prediction is that this overhyping will lead to the claims being challenged legally in the next 12 months [^prediction].

For something to generate text without an understanding of what those words are or what they mean is not intelligence ‚Äì it's a *forgery*. 

ChatGPT didn't learn the topic, it did no research, it did no validation, and it contributed no novel thoughts, ideas or concepts. Other people did all of that already. ChatGPT just colonised all of that data - hovering it up without any permission or legal right to do so, just like all the great white guys of the past - and now it can Copy/Paste that information to you in a timely manner because it's spending $US700k a day on compute. These models don't know the meaning of the words they generated because they base their sequence on probability, not correctness. The words aren't checked for correctness or understanding, but comprehension based on similar blocks of text. 

"Yeah, but it generates new things!"

Does it? On it its own? Does it just come up with entirely new and novel things without, say, a *prompt*?

No. You provided the prompt. You ***had*** to provide the prompt, or nothing would have happened. You provided the creativity. You did the heavy lifting of thought by generating the prompt. What you outsourced was the labour. You *could have* crafted the text yourself, but it would have taken effort. Instead, you outsourced your request to a server farm to process it based on the similarity of the words you were searching for in its colonised and stolen data set.

It's not intelligent; it's sophisticated ‚Äî¬†both the mathematics and the hardware on which they're running.

The fact is that the equation doesn't seek to understand the text or find meaning in it. For it to work, it doesn't need to. Instead, it creates shapes and patterns in a mathematically definable format that it can use to compare and predict similarities and fit because, at some point, other people told it what was correct. It's had years of person-hours telling it where it went wrong and where it was right - we have that too ‚Äì it's called childhood.

The thing is, kids learn **why**. They don't just learn the patterns of behaviour; they learn the causes and effects. They develop an understanding not just of the shape, but the reason for it. They can understand and create meaning not just from the simple but from the complex. Good parenting, guardianship, and solid relationships do this, and it takes effort and time. It is very different to the behaviourist conditioning of "right" and "wrong" [^watters] these models utilise. Children learn across modes, media, instances and locations, social and individual spaces, cultures, and languages. ChatGPT does none of that. It doesn't *understand*. It cannot relate to emotions or tone; it doesn't need to make relationships or maintain or grow them. It doesn't count what it doesn't need. 

It simply spits out words. Just words. Like Clippy.

The above is just about words, but we see the same model being applied to other areas ‚Äî image generation, voice cloning, videos, search, and soon-to-be every app you touch. They operate in the same mode - adapting pixels and bits based on training data they colonised and stole. And we feed them more data without question. Every app that comes out now is there to hoover up the next data set. Yesterday, they came for your words; now, they come for your prompts. Producing more forgeries along the way, and not just some dodgy text - but fake nudes, political lies, news reports, state propaganda, disinformation & misinformation ‚Äì stuff that will have a real and tangible impact on the world, on you and your family and friends.

Don't buy into the hype or the "someday-isms". Look at what's around today. Ask yourself - will AI do anything to fix this, or will it just make it worse?

Will it help you connect with your kid or your partner?
Will it help with climate change or add to it?
Will it create more insidious spam?
Will it just add fuel to the fire?

The thing is ‚Äî regardless of what we choose,¬†all the worst things ***will*** happen. Maybe not to us, but every nightmare will happen somewhere in the world because this technology doesn't understand or mean anything. It doesn't understand the implications of what it creates. It doesn't know the meaning of the words or what the pixels in the image mean to someone - it just makes them happen.

Rather than a superintelligence, we are creating a subprime idiot [^zitron].

---

Read the first post [[The Hype Machine is Breaking Us]]. 


[^prediction]: The biggest threat to AI will be the myriad of legal challenges coming it's way. Governments are too slow and stupid to react, and markets will have lured in all the suckers and have made off with their billions before anything gets settled.

[^watters]: Audrey Watters' work on the influence of the behaviourists on technology and Silicon Valley (see [Teaching Machines](https://direct.mit.edu/books/monograph/5138/Teaching-MachinesThe-History-of-Personalized)) is worth tapping into here.

[^zitron]: While this was in my drafts, this much richer post, [Subprime Intelligence](https://www.wheresyoured.at/sam-altman-fried/)¬†from Ed Zitron, was published. I recommend reading it as it contains links and depth that support for the opinion I shared.